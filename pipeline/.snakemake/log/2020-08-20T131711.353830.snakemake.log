Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 12
Job counts:
	count	jobs
	1	annotANNOVAR
	1	annotINTERVAR
	1	annotVEP
	1	baseRecalibration
	3	bgzip
	1	combineGVCF
	1	combineVCF
	1	createBaseRecalibrationTable
	1	createGVCFList
	3	depthOfCoverage
	1	extractGNOMAD
	1	extractGNOMADVEP
	1	filterIndels
	1	filterSNVs
	1	filtrationVEP
	1	freqGNOMAD
	1	genotypeGVCF
	1	gunzipCADD
	1	haplotypeCaller
	1	indelRealign
	1	markDuplicates
	1	merge
	1	picardMetrics
	1	realignTargetCreator
	1	scoreCADD
	1	selectIndels
	1	selectSNVs
	3	tabix
	1	target
	35

[Thu Aug 20 13:17:11 2020]
rule merge:
    input: Samples/Sample1/BAM/Sample1.p1.sorted.bam
    output: Samples/Sample1/BAM/Sample1.merged.bam, Samples/Sample1/BAM/Sample1.merged.bai
    jobid: 37
    reason: Missing output files: Samples/Sample1/BAM/Sample1.merged.bai, Samples/Sample1/BAM/Sample1.merged.bam
    wildcards: sample=Sample1

Submitted job 37 with external jobid 'Your job 4087459 ("snakejob.merge.37.sh") has been submitted'.
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Cancelling snakemake on user request.
