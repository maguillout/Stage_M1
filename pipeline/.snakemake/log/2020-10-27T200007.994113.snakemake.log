Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 12
Job counts:
	count	jobs
	1	merge_fields
	1	target
	2

[Tue Oct 27 20:00:08 2020]
rule merge_fields:
    input: VCF/hapcaller.recal.combined.annot.gnomad.vep.filtered.annovar.vcf.hg19_multianno.txt, CSV/res_intervar.Sample1.hg19_multianno.txt.intervar, CSV/gnomad_vep.tsv, CSV/cadd.tsv
    output: CSV/individual_results_Sample1.tsv
    jobid: 3
    reason: Missing output files: CSV/individual_results_Sample1.tsv
    wildcards: sample=Sample1

Submitted job 3 with external jobid 'Your job 4305542 ("snakejob.merge_fields.3.sh") has been submitted'.
[Tue Oct 27 20:00:28 2020]
Error in rule merge_fields:
    jobid: 3
    output: CSV/individual_results_Sample1.tsv
    cluster_jobid: Your job 4305542 ("snakejob.merge_fields.3.sh") has been submitted

Error executing rule merge_fields on cluster (jobid: 3, external: Your job 4305542 ("snakejob.merge_fields.3.sh") has been submitted, jobscript: /sandbox/shares/nextcloud/mguillout/files/Application/pipeline/testVB_10/.snakemake/tmp.vknpovf8/snakejob.merge_fields.3.sh). For error details see the cluster log and the log files of the involved rule(s).
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /sandbox/shares/nextcloud/mguillout/files/Application/pipeline/.snakemake/log/2020-10-27T200007.994113.snakemake.log
